---
title: 'Graph Neural Networks'
date: 2023-12-01
permalink: 
tags:
  - Graphs
  - Graph Neural Networks
  - PyTorch Geometric
---

Have you ever heard about **graphs**? What about **graph neural networks (GNNs)**? 
If you have never paid attention, let's try to remind you that, structures like the
image below are, actually, _graphs_. And they are filling all the internet.

![](https://i0.wp.com/backgroundabstract.com/wp-content/uploads/edd/2022/01/gradient-network-connection-background_23-2148865392-e1656081168680.jpg?fit=626%2C417&ssl=1)
###### Figure 1: [A simple image background, that you can find anyplace in the internet.](https://i0.wp.com/backgroundabstract.com/wp-content/uploads/edd/2022/01/gradient-network-connection-background_23-2148865392-e1656081168680.jpg?fit=626%2C417&ssl=1)

Let's go with me, to learn a bit about this amazing technique, able to tackle problems 
beyond the usual _tabular data_ from the day-to-day to Cosmology!

This post can be followed in a Jupyter Notebook using my repo: [https://github.com/natalidesanti/pytorch_and_GNNs](https://github.com/natalidesanti/pytorch_and_GNNs)

Different data sets
--------------------------

Most of the time, we have a simple _tabular data_ and we would like to make predictions given some columns (the _input data_) and other
columns (the _target data_) of that table, which you would like to make some predictions using the input. 
This is the simplest idea behind "doing" traditional **machine learning**. 
What this kind of data has is that it is what we call a **structured data set**. 
This means that you will always have your _input_ with the same shape, because the object you are trying to use to learn predictions
has always the same number of features.

The problem arises when we have **unstructured data** and this kind of data is everywhere because everything can be translated into
a _graph_. In other words, this means you can have different _input data_ with different "number of objects" (what we will call, in
the graph structure, as **nodes**). And the beautiful thing here is that these different "pieces of data" have structure by themselves,
in the way that we define each node containing a fixed number of **node features**.
You can think about _unstructured data_ as a set of tables, each one with a different number of rows.
This is the kind of data **GNNs** are amazing to deal with!

![](https://raw.githubusercontent.com/natalidesanti/natalidesanti.github.io/master/images/structuresxunstructured_data.jpg)
###### Figure 2: [A representation of structured X unstructured data sets.](https://raw.githubusercontent.com/natalidesanti/natalidesanti.github.io/master/images/structuresxunstructured_data.jpg)

What is a graph?
----------------------------

**Graphs** are mathematical units represented by $3$ numbers: $G = G (n_i, e_{i j}, g)$:
* $n_i$: node attributes (properties related to the objects translated into graphs)
* $e_{i j}$: edge attributes (usually properties related to the two nodes in question)
* $g$: global attribute (which represents the entire graph)

![](https://blog.fastforwardlabs.com/images/editor_uploads/2019-10-25-173715-graph_basics.png)
###### Figure 3: The idea of a graph - [Image source: [https://blog.fastforwardlabs.com/images/editor_uploads/2019-10-25-173715-graph_basics.png](https://blog.fastforwardlabs.com/images/editor_uploads/2019-10-25-173715-graph_basics.png)]

(Almost) everything can be translated into a **graph**!

Let's built the most simple graph ever: a graph with $3$ nodes: $[0, 1, 2]$, with node attributes $x_1 \in [-1, 0, 1]$ and $4$ edges (lines that take one node to another, as well theirs vice versa):

![](https://pytorch-geometric.readthedocs.io/en/latest/_images/graph.svg)
###### Figure 4: A simple graph, with all its information

`edge_index = torch.tensor([[0, 1], [1, 0], [1, 2], [2, 1]], dtype = torch.long) #Edge indexes`
`x = torch.tensor([[-1], [0], [1]], dtype = torch.float) #Node attributes`
`g = torch.tensor( [[3]], dtype = torch.int ) #Global attribute (number of nodes)`
`graph = Data(x = x, edge_index = edge_index.t().contiguous(), u = g)`

To visualize it we can just use:

`plt.figure(dpi = 100)`
`plt.title('Example of a graph colored by their node attribute')`
`G = to_networkx(graph, to_undirected = True)`
`nx.draw(G, node_color = graph.x[:, -1], node_size = 300, with_labels = True)`

![](https://raw.githubusercontent.com/natalidesanti/natalidesanti.github.io/master/images/simple_visualization-graph.png)
###### Figure 5: An example of what you will see with the piece of code - a graph, colored by their node information

A simple problem: predicting the center of mass of a box
----------------------------

In order for me, to explain how GNNs work, I will let you think about a simple problem with me.
Imagine we need to compute the **center of mass** of some boxes, which contain some particles inside them.

![](https://studyingphysics.files.wordpress.com/2012/10/system-of-particles.jpg)
###### Figure 6: Center of mass definition - [Image source: [https://studyingphysics.files.wordpress.com/2012/10/system-of-particles.jpg](https://studyingphysics.files.wordpress.com/2012/10/system-of-particles.jpg)]

